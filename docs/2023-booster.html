<!doctype html>
<html>

<head>
	<meta charset="utf-8">
	<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=10.0, user-scalable=yes">

	<title>Workshop Booster Conf 2023</title>

	<link rel="stylesheet" href="revealjs/reveal.js/dist/reset.css" />
    <link rel="stylesheet" href="revealjs/reveal.js/dist/reveal.css" />
    <link rel="stylesheet" href="revealjs/reveal.js/dist/theme/white.css" />

    <!-- Theme used for syntax highlighted code -->
	<!-- <link rel="stylesheet" href="revealjs/reveal.js/plugin/highlight/monokai.css"> -->
	<!-- <link rel="stylesheet" href="revealjs/reveal.js/plugin/highlight/zenburn.css"> -->
    <link rel="stylesheet" href="revealjs/highlight-js-github-theme.css" />
    <link rel="stylesheet" href="revealjs/styles.css" />

</head>

<body style="background-color: whitesmoke;">
	<div class="reveal">
		<div class="slides">

<section data-markdown class="todo">
	<textarea data-template>
### Bias / Fairness

* Über der Oberfläche
  * Widersprüchliche Metriken
  * Accuracy-Fairness-Tradeoff
  * Bias bereits in Trainingsdaten
  * Wer entscheidet was Fair ist?
  * Gruppenbasierte vs individuelle Fairness
* Unter der Oberfläche
  * Proxy Variablen (nicht Einkommen oder Alter, sondern PLZ)
  * Data- oder Concept-Drift
  * Ist eine algorithmische Lösung möglich und angemessen
  * Einspruch gegen algorithmische Entscheidung möglich?
  * Keine Ground-Truth in Production
  * Datenschutz vs Fairness
  * Nützt Fairness dem Geschäft?
  * Beim manuellem Labelling können Labels Weltanschauung in Bias der Annotierenden enthalten
  * Zementierung bestehender Machtstrukturen
  * Unmöglichkeit eindeutiger Kategorisierung (z.B. Geschlecht, sexuelle Orientierung)
</textarea>
</section>


<!-- 

Resilient Machine Learning
- Unwanted Bias
  - https://www.techtarget.com/searchenterpriseai/definition/machine-learning-bias-algorithm-bias-or-AI-bias
- Adversarial Attacks
  - http://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture16.pdf
    - https://www.youtube.com/watch?v=CIfsB_EYsVI&list=PLSVEhWrZWDHQTBmWZufjxpw3s8sveJtnJ
  - https://github.com/smasis001/mlconf-2022
  - https://odsc.medium.com/detecting-adversarial-attacks-with-subset-scanning-8a53c360512f
  * Seldon Alibi Detect: https://docs.seldon.io/projects/alibi-detect/en/stable/ad/methods.html
  * ART
    * https://developer.ibm.com/articles/applying-the-adversarial-robustness-toolbox/
    * https://github.com/Trusted-AI/adversarial-robustness-toolbox

- Out-of-distribution Robustness
  - http://www.gatsby.ucl.ac.uk/~balaji/balaji-odsc-talk.pdf
- Reliable measure of certainty of prediction  
  - http://www.gatsby.ucl.ac.uk/~balaji/balaji-odsc-talk.pdf
- Drift
- Stability
  - https://djcordhose.github.io/ai/2019_m3_embeddings.html#/32
  - https://djcordhose.github.io/ai/2019_m3_embeddings.html#/36
- Fallbacks / Ensembles
  - https://danshiebler.com/2022-07-04-resilient-machine-learning/


Resilience is known as the ability to adapt to difficult or unexpected situations. Such a phenomenon also exists in the field of machine learning, where we have to deal with adversarial attacks, 
out-of-distribution robustness, and drift. Model stability must be ensured during retraining and post-training.
Measures include monitoring machine learning models, detecting outliers, and running with fallbacks and/or multiple models as an ensemble.
Clever model selection for production can also go a long way. In this talk, I explain the phenomena mentioned and address the appropriate measures for each.

---
https://dsco.usfdatainstitute.org

Resilient Machine Learning

Resilience is known as the ability to adapt to difficult or unexpected situations. Such a phenomenon also exists in the field of machine learning, where we have to deal with adversarial attacks, out-of-distribution robustness, drift, and unwanted bias. Additionally, model stability must be ensured during retraining and post-training.
Measures include monitoring machine learning models, detecting outliers, and running with fallbacks and/or multiple models as an ensemble.
Clever model selection for production can also go a long way. 

In this talk, I explain the phenomena mentioned and address the appropriate measures based on an example in the field of computer vision, which poses additional challenges.


Bio: Oliver is a software developer and architect from Hamburg, Germany. He has been developing software with different
approaches and programming languages for more than 3 decades. Lately, he has been focusing on Machine Learning and its interactions with humans.

Title: Head of AI / AI Strategist

https://www.linkedin.com/in/oliver-zeigermann-34989773/
---
M3
https://www.m3-konferenz.de/cfp.php

Resilientes Machine Learning

Resilienz ist die Fähigkeit der Anpassung an schwierige oder unerwartete Situationen.
Eine solche Widerstandskraft kann es bei Menschen geben oder eben auch in Softwaresystemen.
Bei klassischen Softwaresystemen betrifft Resilienz häufig nur die Ausfallsicherheit.
Mit der Nutzung von Machine Learning innerhalb der Systeme kommen viele weitere Aspekte hinzu. Eine Besonderheit ist
hier eine komplexe Geschäftslogik, die als ein abstraktes Artefakt vorliegt. Diese unterliegt nicht mehr vollständig der
Kontrolle der Entwickler.
Als Konsequenz müssen wir uns mit Phänomenen wie Adversarial Attacks, Out-of-Distribution Robustness und Drift
auseinandersetzen.
Die Stabilität des Modells muss hier bei Neutraining und Nachtraining gewährleistet werden.
Maßnahmen umfassen das Monitoring von Machine Learning-Modellen, die Erkennung von Ausreißern und den Betrieb mit
Fallbacks und/oder mehreren Modellen als Ensemble.
Auch eine geschickte Auswahl des Modells für die Produktion kann schon viel bewirken.
In diesem Talk erläutere ich die genannten Phänomene und gehe auf die jeweils passenden Maßnahmen ein.

Kurze Version


Resilienz ist die Fähigkeit der Anpassung an schwierige oder unerwartete Situationen.

Im Bereich des Machine Learnings müssen wir uns dabei mit Phänomenen wie Adversarial Attacks, Out-of-Distribution Robustness und Drift auseinandersetzen.
Die Stabilität des Modells muss hier bei Neutraining und Nachtraining gewährleistet werden.
Maßnahmen umfassen das Monitoring von Machine Learning-Modellen, die Erkennung von Ausreißern und den Betrieb mit Fallbacks und/oder mehreren Modellen als Ensemble.
Auch eine geschickte Auswahl des Modells für die Produktion kann schon viel bewirken.
In diesem Talk erläutere ich die genannten Phänomene und gehe auf die jeweils passenden Maßnahmen ein.

Vorkenntnisse

Grundverständnis vom Training von Machine Learning Modellen

Lernziele

Ein Einblick in die Welt des Machine Learnings in Produktion und was man beachten muss, Nachts gut schlafen zu können.


---
Booster mit Hanna

Gamifying MLOps - Experiencing Machine Learning Operations

Getting machine learning into production and keeping it there is the topic of Machine Learning Operations (MLOps). In
order to get a feeling for this, we will let you play through the phases of a machine learning project that you have to
get into production and keep there for as long as possible to profit from it.
Along the way, events occur that influence the setting and show whether you made the right choices or not. This way you
can experience what it feels like to have a machine learning model in production instead of only talking about it.
We will bring a couple of game sets, so even though the number of participants will be limited, there will be a good
amount of people who can join in.
You will need no prior knowledge of machine learning and you don't even have to be a technical person to participate.


Bio Hanna: 

Hanna started her career as a researcher in linguistics but then decided to pursue another Master's degree in
Computer Science and to work as a developer. She sees Machine Learning as a great way to combine the thinking part of
her first career choice with the acting part of her second career choice.

Bio Olli:

Oliver is a software developer and architect from Hamburg, Germany. He has been developing software with different
approaches and programming languages for more than 3 decades. Lately, he has been focusing on Machine Learning and its
interactions with humans.

Any equipment needed?

We will bring the game sets, but we need 5 tables and 5 chairs around each table. 

---

ODSC Europe / Pydata Berlin

Mischung als Resilient ML wie bei M3 und dem was ich mit Hanna erfolglos bei der MLConference eingereicht habe


"Fit a model on a given dataset sampled from a distribution that represents our problem" could be a casual way of describing the classic idea of machine learning.
 
This, however, does not reflect the challenges of many modern machine learning projects. Data does not simply exist and the sample people are working on often is not static, but rather gets generated incrementally in smaller batches. Also, the distribution the data is sampled from can change with the domain it comes from.

In this talk we will address the following questions:
- Workflow: What kind of workflow reflects a more incremental take on machine learning?
- Training for Production: How can we anticipate if our model works well in production and when to retrain?
- Explainability: How can we find out how our model works to check for bias and analysis of degradation?
- Unwanted Bias: Data sampled in the past is used to predict the future. How can we find out if our model has bias that is (no longer) wanted?
- Testing: What is a proper way of testing a model to find regressions from previous cycles?
- Monitoring: How do we detect when our model actually degrades in production and how do we react?

Material 
- OK, debates about the necessity or "priors" (or lack thereof) in learning systems are pointless.
Here are some basic facts that all ML theorists and most ML practitioners understand, but a number of folks-with-an-agenda don't seem to grasp.
Thread.
1/
(https://twitter.com/ylecun/status/1591463668612730880?t=eyUG-2osacHHE3fDMDgO3g&s=03) 
  - 

Bereiche
- Bilderkennung
  - Klassische Bildverarbeitung
    * OpenCV
  - Convolutional Neural Networks (CNNs)
    * https://teachablemachine.withgoogle.com/
  - Object Detection, Retina-Net
    * https://towardsdatascience.com/retinanet-how-focal-loss-fixes-single-shot-detection-cb320e3bb0de
- Anomalie-Erkennung
  - Autoencoder
    * https://anomagram.fastforwardlabs.com
  - Clustering / Ausreißererkennung    
  - Statistische Verfahren (Z-Scores)
- Text-Klassifikation
  - Transformer, z.B. BERT
    * https://huggingface.co/models
  - Large Language Models (LLMs, im Prinzip auch Transformer, aber eben in (noch?) unpraktikabel riesig und nicht lokal gehostet, z.B. GPT-3
    * https://openai.com/api/
  - Copilot
    * https://github.com/features/copilot
- Vorhersage
  - Lineare/Logistische Regression
  - Statistische Verfahren (Moving Windows)
  - Neuronal Netzwerke
    * https://playground.tensorflow.org/

---
 
Machine Learning in der Cloud 

Die Möglichkeiten des Einsatzes von Machine Learning in der Cloud reichen von der reinen Nutzung bestehender Modelle bis
hin zu Design, Training und Produktivsetzung von eigenen Modellen. Container-Lösungen bieten zudem eine reproduzierbare Plattform für
Trainings- und Validierungs-Prozesse.

In diesem Talk führen wir dich in die Grundlagen von Containern und der Cloud ein, zeigen, auf welche Arten die Cloud
bei Machine Learning Projekten hilfreich sein kann und welche Anbieter mit welchem Angebot es gibt. Auf Basis unserer
Erfahrung mit diesen Möglichkeiten und Angeboten runden wir den Talk mit unseren Einschätzungen und Empfehlungen ab.

Bio Olli Option 1:
Oliver Zeigermann arbeitet als Entwickler, Architekt und Berater. Er interessiert sich für die Überschneidungen und
Unterschiede vielfältiger Arten der Softwareentwicklung.

Bio Olli Option 2:
Oliver Zeigermann ist Softwareentwickler aus Hamburg. Er entwickelt seit über 35 Jahren Software mit unterschiedlichen
Ansätzen und Programmiersprachen. In letzter Zeit hat er sich vor allem mit Machine Learning und dessen Kommunikation
mit dem Menschen beschäftigt. Oliver verantwortet bei der open knowledge GmbH den Bereich Machine Learning und KI.
-->

<!-- <section data-markdown class="preparation">
	<textarea data-template>
### Vorbereitung

* Stift einsatzbereit (geladen)
* Probelauf Drift Detection
* Installation einmal platt machen: `docker compose down --volumes --rmi all`
* Und wieder hoch fahren dabei alles neu bauen und alle images neu ziehen: `docker compose up --build`
</textarea>
</section>

<section data-markdown class="todo">
	<textarea data-template>
### Stichworte von ODSC

* Warum selten Trainieren
  - different Model, unexpected traits
  - manual inspection is typically necessary
  - Metrics having thresholds will not be good enough when images or texts are the input 
  - Stability: an ML model is a complex system, people need to make themselves familiar with it. Would you like to have a new character trait in your colleagues every day?
</textarea>
</section>

<section data-markdown class="todo">
	<textarea data-template>
###  Uncertainty and Out-of-distribution Robustness in Deep Learning

http://www.gatsby.ucl.ac.uk/~balaji/balaji-odsc-talk.pdf
http://www.gatsby.ucl.ac.uk/~balaji/balaji-siam-uq-2022-invited-talk.pdf
</textarea>
</section>
 -->


<!-- <section data-markdown class="todo">
  <textarea data-template>

Despite the growing recognition of AI/ML as a crucial pillar of digital transformation, successful deployments and
effective operations are a bottleneck for getting value from AI. Only one in two organizations has moved beyond pilots
and proofs of concept.

https://services.google.com/fh/files/misc/practitioners_guide_to_mlops_whitepaper.pdf
https://cloud.google.com/blog/topics/developers-practitioners/using-vertex-ai-rapid-model-prototyping-and-deployment
</textarea>
</section>
 -->

SOFTWARE ARCHITECTURE IS NOT A SWEARWORD

Workshop 1.5 hour - Suggested by Oliver Zeigermann

Within the community of coders “being an architect” or “doing
architecture” is often looked down upon. When referring to
architecture we often mean drawings of boxes and arrows that are
pointless and have not relation to what is really being done.

However, architecture can also be defined as the important decision,
whatever they are (https://martinfowler.com/architecture/). There
always are important decisions and the code only contains the how and
not the why. Such decisions often have to be made early in a project,
require compromise and if being bad have the potential to make the
project fail.

In this workshop we will look at the important decisions of projects,
how to identify and justify then. This is independent of any
technology or approach. We will also discuss how to document those
decisions, so people actually trust them to be relevant and up to
date.

There will be exercises on paper to be solved in teams.

---

Altes Material zu Software Architektur:

https://docs.google.com/document/d/17ErlTk8M66dAGowj60e3d-dERPVPwIP5Trkxzr9BGNQ/edit

---

Was macht Software schwer? Wo stecken die wichtigsten Architektur-Entscheidungen?

Wo steckt die meiste Arbeit drin, was kann man am dollsten in der Architektur verkacken?

- Logik
- UX
- Skalierbarkeit

Nicht CRUD oder Hello World

Wir heute: Logik


Weiteres wichtiges Thema in Dev: Wie managen wir Änderungen?
- UX
- API
- Major/Minor
---

<section data-markdown class="todo">
  <textarea data-template>
# Intro    
- TL'DR 
- I try to be less arrogant , but when I see a talk or when in a meeting someone starts to draw boxes and arrows, I internally shut down.
- MBA Witz
- Wann machen boxen und arrows Sinn
</textarea>
</section>

<section data-markdown class="todo">
  <textarea data-template>
- Wie ML Spiel machen? Da die Entscheidungen einbauen und den Ablauf durch die Ergebnisse simulieren?
- Documentation wo?
</textarea>
</section>

<section data-markdown class="todo">
  <textarea data-template>
# Folien, Story    
- Ganz am Anfang des Workshops das Spiel erläutern und damit die Story schon klar haben 
- Eigenschaften des Modells nach vorn ziehen
  - Adversarial, Stability etc.
</textarea>
</section>



			<section data-markdown>
				<textarea data-template>
## MLOps – wo Machine Learning auf Softwareentwicklung trifft

MAD 2022, https://mad-summit.de/fundamentals/mlops-wo-machine-learning-auf-softwareentwicklung-trifft/

Hanna Lüschow / hanna.lueschow@openknowledge.de

Oliver Zeigermann / oliver.zeigermann@openknowledge.de

Folien: https://bit.ly/mad-2022-mlops
<br>
<img src="img/mad-qr.png" style="height: 200px;">

    </textarea>
			</section>

      <section data-markdown class="preparation">
  <textarea data-template>
### Arbeitsblätter      

1. Entscheidung welcher ML Ansatz: <a href='arbeitsblaetter/Steckbriefe.pdf'>arbeitsblaetter/Steckbriefe.pdf</a>
1. Spielregeln / Kosten / Gewinn / Ereignisse: <a href='arbeitsblaetter/Spielregeln.pdf'>arbeitsblaetter/Spielregeln.pdf</a>
1. Spiel-Tabelle: <a href='arbeitsblaetter/Kalkulationsblatt.pdf'>arbeitsblaetter/Kalkulationsblatt.pdf</a>

  </textarea>
</section>


<section data-markdown>
  <textarea data-template>
### Wer ist Hanna

<img src='img/Hanna-Lueschow-6.jpg'>

<p>
<a target="_blank" href="mailto:hanna.lueschow@openknowledge.de">Hanna Lüschow</a>:
Dev@OPEN KNOWLEDGE
</p>    
</textarea>
</section>

<section data-markdown>
  <textarea data-template>
### Wer ist Olli

<img src='img/olli-opa.jpeg'>

<p>
<a target="_blank" href="mailto:oliver.zeigermann@openknowledge.de">Oliver Zeigermann</a>:
ML Stratege@OPEN KNOWLEDGE
</p>    
</textarea>
</section>

<section data-markdown>
	<textarea data-template>
## Ablauf

### Teil I
1. Intro
1. Spielregeln
1. ML Ansätze
1. Spielrunde 1

### PAUSE

### Teil II 
1. Drift verstehen
1. Spielrunde 2
1. Abschluss, Zusammenfassung
</textarea>
</section>

<section data-markdown>
	<textarea data-template>
### Gruppen und Umfrage

1. Tut euch mit euren Nachbarn in Gruppen von 4-5 Menschen zusammen
1. Stellt euch kurz einander vor, z.B.
   * Was macht ihr?
   * Was wisst ihr schon?
   * Warum seid ihr hier?
1. Umfrage im Plenum  
</textarea>
</section>

<section data-markdown>
	<textarea data-template>
## Ablauf

### Teil I
1. *Intro*
1. Spielregeln
1. ML Ansätze
1. Spielrunde 1

### PAUSE

### Teil II 
1. Drift verstehen
1. Spielrunde 2
1. Abschluss, Zusammenfassung
</textarea>
</section>


<section data-markdown>
  <textarea data-template>
<img src="img/ml-vs-dev-1.png">		
  </textarea>
</section>

<section data-markdown>
  <textarea data-template>
<img src="img/ml-vs-dev-2.png">		
  </textarea>
</section>

<section data-markdown>
  <textarea data-template>
### KI vs Machine Learning vs Deep Learning

<img src="img/KI.png">		
  </textarea>
</section>

<section data-markdown>
  <textarea data-template>
### Wozu machen wir ML?
    
<img src="img/ml-muster-aktion.png">		
  </textarea>
</section>

<section data-markdown class="fragments">
  <textarea data-template>
### Wann ist KI/ML sinnvoll?

* Die Lösung des vorliegenden Problems ist unbekannt oder _schwer zu spezifizieren_
* Es liegen _Daten_ mit einer klaren, einfachen Eingabe und bestenfalls auch passender Ausgabe vor
* Es gibt _Muster_ in der Eingabe, auf die reagiert werden kann
* Die Lösung des Problems kann Fehler oder _Unsicherheiten_ tolerieren
  * _80% Genauigkeit_ werden selten übertroffen
* Wir sind bereit und in der Lage, in einer initialen Phase _Experimente mit offenem Ausgang_ durchzuführen
</textarea>
</section>


<section data-markdown>
  <textarea data-template>
### Phasen eines ML Projekts

<img src="img/ml-workflow/6.PNG" class="fragment">

</textarea>
</section>

  <section data-markdown class="fragments">
###  Was brauchen wir für eine Überprüfung eines Anwendungsfalls?

1. Erhofften *Geschäftsnutzen*
1. eine *Metrik* als Maß des Erfolgs
1. Verfügbare *Daten*
1. (Machine Learning-)*Ansatz*
1. *Rahmenbedingungen*

</section>

  <section data-markdown>
    <textarea data-template>
### Typische Rahmenbedingungen

* Datenschutz
* Erklärbarkeit
* Performance / Latenz
  * Prediction
  * Training
* Welche Genauigkeit brauchen wir für unseren Anwendungsfall?
  * Welche Metrik: Accuracy vs False Negatives vs False Positives
  * Fallbacks
* Unerwünschte Biases
* Stabilität: wenn mit neuen, aber ähnlichen Daten trainiert wird, sollte sich das Modell vergleichbar verhalten 

</textarea>
</section>  

<section data-markdown class="fragments">
### Was ist MLOps?

* MLOps ist abgeleitet von DevOps
* Durch MLOps kommt ML in Produktion und wird in Betrieb gehalten
* Dazu kommen eine Reihe von Werkzeugen und Praktiken zum Einsatz
* Überschneidung aus
  * Softwareentwicklung
  * Operations
  * Data Science
</section>

<section data-markdown class="fragments">
### Warum MLOps?

* im akademischen Leben zählt für einen Wettbewerb häufig nur der Score (Güte) des Modells
* dieser Ansatz hat sich im Bereich des Data Science auch in der Praxis breit gemacht
* die Praxis ist aber keine Kaggle Competition
* In-Sample Evaluation (auch wenn wir die vorher abgetrennt haben) sagt nur bedingt etwas für Eignung in
einer praktischen Anwendung aus
* Out-Of-Sample Evaluation häufig erst im produktiven Betrieb möglich (evtl nur mitlaufen lassen)
</section>

<section data-markdown>
	<textarea data-template>
## Ablauf

### Teil I
1. Intro
1. *Spielregeln*
1. ML Ansätze
1. Spielrunde 1

### PAUSE

### Teil II 
1. Drift verstehen
1. Spielrunde 2
1. Abschluss, Zusammenfassung
</textarea>
</section>


<section data-markdown>
  <textarea data-template>
## Spielidee    

Zusammen in der Anleitung durchgehen

<a href='arbeitsblaetter/Spielregeln.pdf'>arbeitsblaetter/Spielregeln.pdf</a>
  </textarea>
</section>  

<section data-markdown>
	<textarea data-template>
## Ablauf

### Teil I
1. Intro
1. Spielregeln
1. *ML Ansätze*
1. Spielrunde 1

### PAUSE

### Teil II 
1. Drift verstehen
1. Spielrunde 2
1. Abschluss, Zusammenfassung
</textarea>
</section>


<section data-markdown>
  <textarea data-template>
### Features

<img src="img/features.jpg">
  </textarea>
</section>  

<section data-markdown>
	<textarea data-template>
## Basis-Satz von Regeln

```
if training: 
    return LOW_RISK
if age < 30:
    if power > 130:
        return HIGH_RISK
    else:
        return MEDIUM_RISK
if age > 50:
    return HIGH_RISK
if emergency_braking:
    return LOW_RISK
if milage > 50:
    return HIGH_RISK
if milage > 30:
    return MEDIUM_RISK
# default
return LOW_RISK
```
</textarea>
</section>

<section data-markdown>
  <textarea data-template>
### ML Ansätze

<a href='https://ml-playground.com'><img src='img/ml-playground.png' style="height: 400px"></a>

https://ml-playground.com
  </textarea>
</section>

<section data-markdown>
  <textarea data-template>
### Steckbriefe in der Zusammenfassung als Kandidaten für eure Ansätze

_die wichtigste Architektur-Entscheidung_

1. Deep Learning: 3 Dense-Schichten mit jeweils 100 Neuronen, auf allen 6 Features 
1. KNN: Nächste Nachbarn auf den Features Alter und Leistung
1. Decision Tree: auf allen 6 Features
1. Regelsystem: auf allen 6 Features

<a href='arbeitsblaetter/Steckbriefe.pdf'>arbeitsblaetter/Steckbriefe.pdf</a>
</textarea>
</section>

<section data-markdown>
	<textarea data-template>
## Ablauf

### Teil I
1. Intro
1. Spielregeln
1. ML Ansätze
1. *Spielrunde 1*

### PAUSE

### Teil II 
1. Drift verstehen
1. Spielrunde 2
1. Abschluss, Zusammenfassung
</textarea>
</section>

<section data-markdown>
  <textarea data-template>
### Spielrunde 1

<img src="img/spielregeln-durchlauf.png">

<a href='arbeitsblaetter/Kalkulationsblatt.pdf'>arbeitsblaetter/Kalkulationsblatt.pdf</a>

https://onlinewuerfel.de/

  </textarea>
</section>
  
<section data-markdown>
<textarea data-template>
### Bericht der Gruppen

* Bist du zufrieden mit deiner Entscheidung?
* Welche Erkenntnisse hast du in der Spielrunde gehabt?
* Welches Wissen fehlt dir noch?
</textarea>
</section>

<section data-markdown>
	<textarea data-template>
## Ablauf

### Teil I
1. Intro
1. Spielregeln
1. ML Ansätze
1. Spielrunde 1

### PAUSE

### Teil II 
1. *Drift verstehen*
1. Spielrunde 2
1. Abschluss, Zusammenfassung
</textarea>
</section>

<section data-markdown>
  <textarea data-template>
## Drift

</textarea>
</section>

<section data-markdown>
  <textarea data-template>
### ML Systeme sind dynamisch

<img src='img/verfall-2.PNG'>

</textarea>
</section>

<section data-markdown class="fragments">
  <textarea data-template>
### Woher weiß man, dass man ein neues Modell in Produktion braucht?

* Schon in der Explorationsphase prüfen, wie sich das Modell auf neueren Daten verhält
  * Wie schnell degradiert die Performance?
  * Mindestens einmal im Jahr, damit man überhaupt noch weiß, wie es geht
* Wenn die Metrik des Modells in Produktion nachlässt
  * Dafür braucht man die Ground Truth der Daten aus Produktion
  * Manchmal bekommt man diese unmittelbar nach der Vorhersage durch die Reaktion eines menschlichen Benutzers
  * Oft aber auch erst nach nennenswerter Verzögerung 
* *Wenn sich die Verteilung der Daten der Anfragen oder Vorhersagen deutlich von der des Trainings unterscheidet* 

</textarea>
</section>

<section data-markdown>
<textarea data-template>
### Verteilung?

* die wichtigste: Normalverteilung aka Gauß-Verteilung
* Histogramme (Binning)

<img src="img/nobel.svg">

</textarea>
</section>


<section data-markdown class="fragments">
  <textarea data-template>
### Verteilungen

<img src="img/causal-insurance/age-reference.png">

Das Alter der Versicherten zum Zeitpunkt des Trainings
</textarea>
</section>


<section data-markdown class="fragments">
<textarea data-template>
### Zum Zeitpunkt des Trainings?

<img src="img/drift_entschlackt.png" style="height: 100%;">

</textarea>
</section>

<!-- <section data-markdown class="fragments">
<textarea data-template>
### So sieht die Verteilung jetzt aus

<img src="img/causal-insurance/age-current.png">

</textarea>
</section>
-->
<section data-markdown class="fragments">
<textarea data-template>
### Driftet das?

<img src="img/causal-insurance/age_no_drift_p75.png">

</textarea>
</section>

<section data-markdown class="fragments">
<textarea data-template>
### Und das?

<img src="img/causal-insurance/age_drift_p0.png">

</textarea>
</section>

<section data-markdown class="fragments">
<textarea data-template>
### Wie erkennen wir Drift?

* Es wird ein statistischer Test auf den Verteilungen ausgeführt
* Die Anfragen in Produktion werden verglichen mit dem Referenz-Datensatz, den wir zum Training benutzt haben

</textarea>
</section>

<section data-markdown class="fragment">
<textarea data-template>
## Welcher statistischer Test / welche Metrik?

es gibt leider nicht den einen passenden Test

* manche passen nur gut für kleine (< 1000) Datenmengen
* unsere Datenmengen sind größer als 1000
* manche können nicht nur auf numerischen, sondern auch auf kategorischen Daten arbeiten
* wir brauchen beides
<!-- * manche sind zwischen 0 und 1 normiert
* das ist uns eher egal -->
</textarea>
</section>


<section data-markdown>
<textarea data-template>
### Speziell für Drift-Erkennung in Frage kommende Tests

* Kolmogorov-Smirnov-Test
* Population Stability Index
* Kullback-Leibler-Divergenz
* Jensen-Shannon-Distanz  
* Wasserstein-Distanz

https://evidentlyai.com/blog/data-drift-detection-large-datasets
</textarea>
</section>

<section data-markdown  class="fragments">
<textarea data-template>
### Unser Beispiel: Kolmogorov-Smirnov-Test

* numerisch
* wird gerne als Default gewählt, kann bei großen Datenmengen aber zu empfindlich sein
* Vorteil: keine Normalverteilung vorausgesetzt
* ein 'typischer' statistischer Test mit p als Rückgabewert
* Nullhypothese: die beiden Verteilungen sind gleich
* Drift bei p-Wert unter 0.05

*Wann nutzen?* Wenn Drift schnell entdeckt werden muss oder die Datenmengen kleiner ausfallen

</textarea>
</section>

<section data-markdown class="fragments">
<textarea data-template>
### P-Werte

* die statistische Verteilung der jeweiligen Features
* weicht diese in Produktion signifikant von der Verteilung im Training ab? (Nullhypothese: nein)
* diese Abweichung wird über eine Metrik berechnet
* es kommt eine Konfidenz heraus, ob die Nullhypothese stimmt
* unter 5% Konfidenz geht man von einer Abweichung aus <span style="font-size: 0.95rem">(1% oder 0.1% auch möglich)</span>
* das bedeutet, dass es eine 5%-Wahrscheinlichkeit gibt, dass die Verteilungen eigentlich doch gleich sind, man aber nur gerade schlechte Beispiele sieht

</textarea>
</section>

<section data-markdown>
<textarea data-template>
### P-Werte für unsere beiden potentiellen Drifts

<div class="container">
<div class="col">
<img src="img/causal-insurance/age_no_drift_p75.png" style="height: 100%;">
<em>p-Wert (Wahrscheinlichkeit der Nullhypothese) = 75%, also kein Drift</em>
</div>
<div class="col">
<img src="img/causal-insurance/age_drift_p0.png" style="height: 100%;">
<em>p-Wert (Wahrscheinlichkeit der Nullhypothese) < 0,1%, also Drift</em>

</div>
</div>

</textarea>
</section>

<section data-markdown style="font-size: x-large;">
	<textarea data-template>
## Drift erfordert Interpretation

Wenn die Welt sich ändert, ist Drift zu erwarten und damit ok

|   | Positive Interpretation, keine Maßnahme erforderlich  | Negative Interpretation, Maßnahme erforderlich  |
|---|---|---|
| *Data und Prediction Drift*  | wichtige Features haben sich geändert, Modell kommt klar und extrapoliert gut, z.B.: Höheres Alter, mehr Risiko  |  wichtige Features haben sich geändert, Modell extrapoliert nicht sinnvoll |
| *Data aber kein Prediction Drift*  | keine wichtigen Features geändert, das Modell ist robust genug für den Drift  | wichtige Features geändert, Modell extrapoliert nicht sinnvoll |
| *Prediction aber kein Data Drift*  | ???  | wahrscheinlich Concept Drift, neue Analyse der Situation notwendig |
|   |   |   |

</textarea>
</section>

<section data-markdown class="fragments">
## Maßnahmen bei Drift

* *Neue Version des Modells trainieren*
  * Neue Daten aufnehmen (und labeln)
  * Neue Features erzeugen
  * Modell-Architektur ändern (oder fixen) und neu trainieren
* Schnelle Maßnahme
  * Pre-/Post-Processing des Modells neu kalibrieren
  * Schwellwerte für Anwendung anpassen
  * Bestimmte Bereiche ausklammern 
* Sehr schnelle Maßnahme: Fallback
  * Manuell
  * Heuristik / Baseline
</section>

<section data-markdown>
  <textarea data-template>
### Die acht Prinzipien der Linux Foundation für KI

<img src='img/lfai-principles.png' style="height: 100%;">

https://youtu.be/4oUGUC4hIhI?t=228
</textarea>
</section>

<!-- 
<section data-markdown class="fragments">
<textarea data-template>
### Was kann man sonst noch machen

* Outlier-Detection
  * Unser Modell wird nicht extrapolieren können
  * Werte außerhalb des Trainings-Bereichs werden wahrscheinlich unrealistisch sicher vorhergesagt
  * Ausreißer müssen ohne Ground Truth entdeckt werden 
* Adversarial Detection
  * Bestimmte Eingaben können absichtlich eine grob falsche Vorhersage herbei führen 
  * Solche Eingaben können erkannt und korrigiert werden
  * Dazu kann z.B. ein Autoencoder benutzt werden, der die Eingabe korrigiert


<small>https://docs.seldon.io/projects/alibi-detect/en/stable/od/methods.html
<br>
https://docs.seldon.io/projects/alibi-detect/en/stable/ad/methods.html
</small>
</textarea>
</section>
 -->
<section data-markdown>
  <textarea data-template>
### Hacking the system / Adversarial Attacks

https://www.instagram.com/reel/CkQUhLov9_u/?igshid=MDJmNzVkMjY=
</textarea>
</section>

<section data-markdown>
  <textarea data-template>
### Adversarial Attacks

* Bestimmte Eingaben können absichtlich eine grob falsche Vorhersage herbei führen 
  * Solche Eingaben können erkannt und korrigiert werden
  * Dazu kann z.B. ein Autoencoder benutzt werden, der die Eingabe korrigiert
* Libs
  * Seldon Alibi Detect: https://docs.seldon.io/projects/alibi-detect/en/stable/ad/methods.html
  * ART
    * https://developer.ibm.com/articles/applying-the-adversarial-robustness-toolbox/
    * https://github.com/Trusted-AI/adversarial-robustness-toolbox
</textarea>
</section>

<section data-markdown style="font-size: x-large;">
  <textarea data-template>
### Instabilität / Nachhaltigkeit

<div class="container">
  <div class="col">
<br>
<br>


<img src="img/twitter-stability-1.png" style="height: 300px;">    
  </div>
  <div class="col">
    <img src="img/twitter-stability-2.png">    
  </div>

</div>

* https://twitter.com/elonmusk/status/1595457703739944976
* https://twitter.com/elonmusk/status/1593673339826212864

</textarea>
</section>

<section data-markdown>
	<textarea data-template>
## Ablauf

### Teil I
1. Intro
1. Spielregeln
1. ML Ansätze
1. Spielrunde 1

### PAUSE

### Teil II 
1. Drift verstehen
1. *Spielrunde 2*
1. Abschluss, Zusammenfassung
</textarea>
</section>


<section data-markdown>
  <textarea data-template>
# Spielrunde 2    

<a href='arbeitsblaetter/Kalkulationsblatt.pdf'>arbeitsblaetter/Kalkulationsblatt.pdf</a>

https://onlinewuerfel.de/
  </textarea>
</section>
  
<section data-markdown class="fragments">
  <textarea data-template>
### Bericht der Gruppen

1. Wer hat mit welchem Modell gewonnen?
1. Welche üblen Ergebnisse sind eingetreten?
1. Wart ihr zufrieden mit der Auswahl des Modells?
1. Habt ihr Gewinn gemacht?
  </textarea>
  </section>

<section data-markdown>
	<textarea data-template>
## Ablauf

### Teil I
1. Intro
1. Spielregeln
1. ML Ansätze
1. Spielrunde 1

### PAUSE

### Teil II 
1. Drift verstehen
1. Spielrunde 2
1. *Abschluss, Zusammenfassung*
</textarea>
</section>

<section data-markdown class="fragments">
<textarea data-template>
### Zusammenfassung

1. Machine Learning-Projekte können in Phasen gedacht werden
1. In der ersten Phase macht man möglichst schnelle Experimente
1. Sollte sich eine Idee als tragfähig erweisen, professionalisiert man die Idee
1. Dies ist Voraussetzung und Grundlage für Produktion
1. In Produktion ergeben sich besondere Herausforderungen im Bereich Monitoring
1. Typischerweise müssen Machine Learning-Systeme regelmäßig nachtrainiert und gepflegt werden
</textarea>
</section>

<section data-markdown>
  <textarea data-template>
### Spielt das Spiel gern auch mit euren Kollegen

Arbeitsblätter
1. Entscheidung für ML-Ansatz: <a href='arbeitsblaetter/Steckbriefe.pdf'>arbeitsblaetter/Steckbriefe.pdf</a>
1. Spielregeln / Kosten / Gewinn / Ereignisse: <a href='arbeitsblaetter/Spielregeln.pdf'>arbeitsblaetter/Spielregeln.pdf</a>
1. Spiel-Tabelle: <a href='arbeitsblaetter/Kalkulationsblatt.pdf'>arbeitsblaetter/Kalkulationsblatt.pdf</a>

_Schickt uns Feedback und bleibt im Kontakt für Updates_
  </textarea>
</section>

<section data-markdown>
  <textarea data-template>
### Weitere Ideen

* Booster Cards
  * Adversarial Attack Prevention Libraries
  * Explainability Approach
  </textarea>
</section>

		<section data-markdown>
			<textarea data-template>
# Vielen Dank

MLOps – wo Machine Learning auf Softwareentwicklung trifft

Bleibt gern im Kontakt

Hanna Lüschow / hanna.lueschow@openknowledge.de

Oliver Zeigermann / oliver.zeigermann@openknowledge.de
https://www.linkedin.com/in/oliver-zeigermann-34989773/
https://twitter.com/DJCordhose

<img src="img/mad-qr.png" style="height: 200px;">

</textarea>
		</section>

		</div>
	</div>
	<script src="revealjs/reveal.js/dist/reveal.js"></script>
	<script src="revealjs/reveal.js/plugin/notes/notes.js"></script>
	<script src="revealjs/reveal.js/plugin/markdown/markdown.js"></script>
	<script src="revealjs/reveal.js/plugin/highlight/highlight.js"></script>
	<script src="revealjs/config.js"></script>


</body>

</html>